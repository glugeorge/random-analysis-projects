{"cells":[{"cell_type":"markdown","metadata":{"id":"fHQJ6omnn5rk"},"source":["# Modeling Lake Thermal Stratification"]},{"cell_type":"markdown","metadata":{"id":"E_w7noZcoEi7"},"source":["In this notebook, we reproduce physics-guided deep learning models proposed in Read *et al* (2019) and Jia *et al* (2019). We use only the Lake Mendota data in this notebook. \n","\n","Both papers combine state-of-the-art deep learning models with strategies to incorporaate \"guidance\" from known physics that governs the dynamics of lake thermal stratefication. \n","\n","This notebook provides a set of starter codes for [LEAP CPC Spring 2022](https://github.com/leap-stc/LEAPCourse-Climate-Pred-Challenges)[Project 2](https://github.com/leap-stc/LEAPCourse-Climate-Pred-Challenges/tree/main/Project-StarterCodes/Project2-PhysicsML) on\n","\n","+ how to download data,\n","+ how to set up physics-guided loss functions,\n","+ how to setup deep learning models using PyTorch,\n","+ how to pre-train and re-train DL models, with early stopping,\n","+ how to evaluate and visualize model predictions.\n","\n","All the codes in this notebook can be modified to implement research ideas. \n","\n","To start, the **team leader** of each team should \n","+ create in the course folder a folder for project 2.\n","This folder can be used to share notes, data, outputs and codes. See [project 2 description](https://github.com/leap-stc/LEAPCourse-Climate-Pred-Challenges/blob/main/Project-StarterCodes/Project2-PhysicsML/doc/project2_desc.md) for a suggested set up. \n","+ share project 2 folder with all team members.\n","+ team members should add this folder to their drive by creating a shortcut to this shared project folder in their own folder for LEAP CPC.\n","+ go to \"File/Save A Copy in Drive/\" (upper left) and save a copy for your team in the project 2 folder that was just created, under an appropriate subfolder. \n","+ for collaboration, team members should all add a shortcut of their project 2 folder to the folder \"Colab Notebooks\" in the root of your Google Drive. See below for more instructions. \n"]},{"cell_type":"markdown","metadata":{"id":"gwEmKptsAeza"},"source":["# Part 0. Setup Workspace"]},{"cell_type":"markdown","metadata":{"id":"j3ihmc5LAu-d"},"source":["## Import packages and adjust settings"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"lYW9f-Db6Ky-","executionInfo":{"status":"ok","timestamp":1645564053901,"user_tz":300,"elapsed":9152,"user":{"displayName":"Nan Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08028572488762231768"}}},"outputs":[],"source":["%%capture\n","!pip3 install sciencebasepy"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"LEkxFV1RArkN","executionInfo":{"status":"ok","timestamp":1645564063538,"user_tz":300,"elapsed":8332,"user":{"displayName":"Nan Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08028572488762231768"}}},"outputs":[],"source":["import os, random, warnings\n","import numpy as np\n","import pandas as pd\n","import datetime\n","import torch\n","import cv2\n","import re\n","import matplotlib.pyplot as plt\n","import sciencebasepy\n","import urllib.request\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import TensorDataset, DataLoader\n","from google.colab import drive\n","from sklearn import preprocessing\n","from urllib.request import urlopen\n","from zipfile import ZipFile"]},{"cell_type":"markdown","metadata":{"id":"DTbv5k_PxfSx"},"source":["For this project, it is important for the team to set up a shared Google Drive to collaborate using the same notebook, while saving intermediate outputs and results to the shared folder. Therefore"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"cWEy0x4GxwrF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645564078589,"user_tz":300,"elapsed":12952,"user":{"displayName":"Nan Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08028572488762231768"}},"outputId":"3bf907de-5a5f-4584-e537-181aeac1e36f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# mount the drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"1aNurNU_x1ip"},"source":["For this project, we will be using PyTorch, which will benefit tremendously from acceleration by GPU. Make sure that you are on a GPU run time. This notebook runs sufficiently fast without a [Google Colab Pro](https://colab.research.google.com/signup) subscription. However, teams with ambitious plans may need more memory and more computational power offer by a Pro subscription. The Pro subscription is not available to LionMail. You would need to share your project with a personal gmail account to enable the Pro subscription. "]},{"cell_type":"code","execution_count":4,"metadata":{"id":"xm0iYiXex3_e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645564080988,"user_tz":300,"elapsed":88,"user":{"displayName":"Nan Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08028572488762231768"}},"outputId":"94f148b8-bab5-4f3b-820d-6943fb393077"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using cuda device\n"]}],"source":["# check GPU\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print('Using {} device'.format(device))"]},{"cell_type":"markdown","metadata":{"id":"dES7sUeVNn5E"},"source":["## Set Data Directory and Shared Folder\n","\n","Each team should create a shortcut to your project folder in the \"Colab Notebooks\" folder similar to \"LEAP Colab Notebooks/Project 2/.\" There should be a folder for raw data and a folder for outputs. \n","\n","**data_dir** should be set as 'drive/Mydrive/Colab Notebooks/SHARED_FOLDER/Data/', where SHARED_FOLDER is the name of the shared folder."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"4gZPT-2qlzTQ","executionInfo":{"status":"ok","timestamp":1645564089798,"user_tz":300,"elapsed":722,"user":{"displayName":"Nan Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08028572488762231768"}}},"outputs":[],"source":["# need to add shortcut of the shared folder to folder \"/MyDrive/Colab Notebooks/\"\n","# and change the folder name accordingly\n","data_dir = 'drive/MyDrive/Colab Notebooks/LEAP Colab Notebooks/Project 2/Data/'\n","output_dir = 'drive/MyDrive/Colab Notebooks/LEAP Colab Notebooks/Project 2/Output/'\n","if not os.path.isdir(data_dir): os.mkdir(data_dir) ## create the folder\n","if not os.path.isdir(output_dir): os.mkdir(output_dir) ## create the folder"]},{"cell_type":"markdown","metadata":{"id":"9u4XWc4xT1Fo"},"source":["## Download and Unzip Data\n","\n","This block will only download the data to the shared Google Drive Folder once. By having a designated folder for raw data, you can always delete every files from the folder and re-download all data to start over, in the case some files are overwritten inadvertently. "]},{"cell_type":"code","execution_count":6,"metadata":{"id":"6aVvhVDFnmOr","executionInfo":{"status":"ok","timestamp":1645564107691,"user_tz":300,"elapsed":258,"user":{"displayName":"Nan Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08028572488762231768"}}},"outputs":[],"source":["if os.listdir(data_dir) == []: ## data not downloaded yet\n","    print('Data folder is empty! Download the files now!')\n","    # set the url\n","    zipurl = 'https://github.com/leap-stc/LEAPCourse-Climate-Pred-Challenges/raw/main/Project-StarterCodes/Project2-PhysicsML/data/numpy_files.zip'\n","    # download the file from the URL\n","    zipresp = urlopen(zipurl)\n","    # create a new file on the hard drive\n","    tempzip = open(data_dir + 'numpy_files.zip', \"wb\")\n","    # write the contents of the downloaded file into the new file\n","    tempzip.write(zipresp.read())\n","    # close the newly-created file\n","    tempzip.close()\n","    # re-open the newly-created file with ZipFile()\n","    zf = ZipFile(data_dir + 'numpy_files.zip')\n","    # extract its contents into <extraction_path>\n","    # note that extractall will automatically create the path\n","    zf.extractall(path = data_dir)\n","    # close the ZipFile instance\n","    zf.close()\n","    print('Files all downloaded!')"]},{"cell_type":"markdown","metadata":{"id":"CyVLqEU1iDrS"},"source":["# Part I. Model Pre-training\n","\n","[Data](https://www.sciencebase.gov/catalog/item/5d88ea50e4b0c4f70d0ab3c0) and [original codes](https://zenodo.org/record/3497495#.YgB85_XMIqv) of Read et al (2019) are all publicly available, which makes this reproducibility effort reasonably easy. \n","\n","Read et al (2019) and Jia et al (2019) proposed a [Long short-term memory (LSTM)](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) network for modeling temperature dynamics. The original codes used TensorFlow version 1.0. In this notebook, we adopt this model using [PyTorch](https://pytorch.org/), an open-source ML framework with excellent libraries for deep learning.  \n","\n","As proposed in the papers, physics guidance were introduced in two ways. The first is adding an energy conservation term to the loss funcation. The second is pretraining the LSTM networks using simulation data from the [General Lake Model](https://aed.see.uwa.edu.au/research/models/glm/). \n","\n","In the following, we outline\n","+ Algorithm configering constants\n","+ Set up functions for calculating energy conservation\n","+ Load the data\n","+ Setup the LSTM model\n","+ Train the LSTM model using simulated data"]},{"cell_type":"markdown","metadata":{"id":"t2WP4BCOjM5V"},"source":["## Constants\n","We set the algorithm configuring constants in this part."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"b6tnrsyhBCWl","executionInfo":{"status":"ok","timestamp":1645564136212,"user_tz":300,"elapsed":9466,"user":{"displayName":"Nan Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08028572488762231768"}}},"outputs":[],"source":["# params for LSTM\n","epochs = 300 ## number of max training epochs\n","batch_size = 100 ## batch size in SGD, must be multiplication of n_depths\n","learning_rate = 1e-2 ## learning rate \n","state_size = 7 ## dimension of hidden layers \n","input_size = 9 ## matches with the data, last dimension of x\n","phy_size = 10 ## matches with the data, last dimension of phy\n","elam = 0.005 ## loss weight\n","patience = 3 ## patience in early stopping\n","\n","\n","# params for data transformation\n","npic = 10 #16 #40 stride size\n","N_sec = (npic-1)*2+1 ## window width\n","n_depths = 50 ## matches with data, first dimension of x, also = len(depth_areas)\n","ec_threshold = 24\n","depth_areas = torch.Tensor([\n","        39865825,38308175,38308175,35178625,35178625,33403850,31530150,31530150,30154150,30154150,29022000,\n","        29022000,28063625,28063625,27501875,26744500,26744500,26084050,26084050,25310550,24685650,24685650,\n","        23789125,23789125,22829450,22829450,21563875,21563875,20081675,18989925,18989925,17240525,17240525,\n","        15659325,14100275,14100275,12271400,12271400,9962525,9962525,7777250,7777250,5956775,4039800,4039800,\n","        2560125,2560125,820925,820925,216125]).to(device)\n"]},{"cell_type":"markdown","metadata":{"id":"oj9gJRuvFA_b"},"source":["## Function definitions for calculating ec loss"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"b144t0gHFAEA","executionInfo":{"status":"ok","timestamp":1645564145095,"user_tz":300,"elapsed":342,"user":{"displayName":"Nan Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08028572488762231768"}}},"outputs":[],"source":["def transformTempToDensity(temp):\n","    # converts temperature to density\n","    # parameter:\n","        # @temp: single value or array of temperatures to be transformed\n","    densities = 1000 * (1 - ((temp + 288.9414) * (temp - 3.9863)**2) / (508929.2 * (temp + 68.12963)))\n","    return densities\n","\n","def calculate_lake_energy(temps, densities, depth_areas):\n","    # calculate the total energy of the lake for every timestep\n","    # sum over all layers the (depth cross-sectional area)*temp*density*layer_height)\n","    # then multiply by the specific heat of water \n","    dz = 0.5 # thickness for each layer, hardcoded for now\n","    cw = 4186 # specific heat of water\n","    depth_areas = torch.reshape(depth_areas, (-1, 1))\n","    energy = torch.sum(depth_areas * temps * densities * dz * cw, axis=0)\n","    return energy\n","\n","def calculate_lake_energy_deltas(energies, combine_days, surface_area):\n","    # given a time series of energies, compute and return the differences\n","    # between each time step, or time step interval (parameter @combine_days)\n","    # as specified by parameter @combine_days\n","    time = 86400 #seconds per day\n","    energy_deltas = (energies[1:] - energies[:-1]) / (time * surface_area)\n","    return energy_deltas\n","\n","def calculate_vapour_pressure_saturated(temp):\n","    # returns in miilibars\n","    # Converted pow function to exp function workaround pytorch not having autograd implemented for pow\n","    exponent = (9.28603523 - (2332.37885 / (temp + 273.15))) * np.log(10)\n","    return torch.exp(exponent)\n","\n","def calculate_vapour_pressure_air(rel_hum, temp):\n","    rh_scaling_factor = 1\n","    return rh_scaling_factor * (rel_hum / 100) * calculate_vapour_pressure_saturated(temp)\n","\n","\n","def calculate_wind_speed_10m(ws, ref_height = 2.):\n","    # from GLM code glm_surface.c\n","    c_z0 = torch.tensor(0.001) #default roughness\n","    return ws * (torch.log(10.0 / c_z0) / torch.log(ref_height / c_z0))\n","\n","def calculate_air_density(air_temp, rh):\n","    # returns air density in kg / m^3\n","    # equation from page 13 GLM/GLEON paper(et al Hipsey)\n","    # Ratio of the molecular (or molar) weight of water to dry air\n","    mwrw2a = 18.016 / 28.966\n","    c_gas = 1.0e3 * 8.31436 / 28.966\n","\n","    # atmospheric pressure\n","    p = 1013. #mb\n","\n","    # water vapor pressure\n","    vapPressure = calculate_vapour_pressure_air(rh, air_temp)\n","\n","    # water vapor mixing ratio (from GLM code glm_surface.c)\n","    r = mwrw2a * vapPressure / (p - vapPressure)\n","    return (1.0 / c_gas * (1 + r)/(1 + r / mwrw2a) * p / (air_temp + 273.15)) * 100\n","\n","def calculate_heat_flux_sensible(surf_temp, air_temp, rel_hum, wind_speed):\n","    # equation 22 in GLM/GLEON paper(et al Hipsey)\n","    # GLM code ->  Q_sensibleheat = -CH * (rho_air * 1005.) * WindSp * (Lake[surfLayer].Temp - MetData.AirTemp);\n","    # calculate air density \n","    rho_a = calculate_air_density(air_temp, rel_hum)\n","\n","    # specific heat capacity of air in J/(kg*C)\n","    c_a = 1005.\n","\n","    # bulk aerodynamic coefficient for sensible heat transfer\n","    c_H = 0.0013\n","\n","    # wind speed at 10m\n","    U_10 = calculate_wind_speed_10m(wind_speed)\n","    return -rho_a * c_a * c_H * U_10 * (surf_temp - air_temp)\n","\n","def calculate_heat_flux_latent(surf_temp, air_temp, rel_hum, wind_speed):\n","    # equation 23 in GLM/GLEON paper(et al Hipsey)\n","    # GLM code-> Q_latentheat = -CE * rho_air * Latent_Heat_Evap * (0.622/p_atm) * WindSp * (SatVap_surface - MetData.SatVapDef)\n","    # where,         SatVap_surface = saturated_vapour(Lake[surfLayer].Temp);\n","    #                rho_air = atm_density(p_atm*100.0,MetData.SatVapDef,MetData.AirTemp);\n","    # air density in kg/m^3\n","    rho_a = calculate_air_density(air_temp, rel_hum)\n","\n","    # bulk aerodynamic coefficient for latent heat transfer\n","    c_E = 0.0013\n","\n","    # latent heat of vaporization (J/kg)\n","    lambda_v = 2.453e6\n","\n","    # wind speed at 10m height\n","    # U_10 = wind_speed\n","    U_10 = calculate_wind_speed_10m(wind_speed)\n","    # \n","    # ratio of molecular weight of water to that of dry air\n","    omega = 0.622\n","\n","    # air pressure in mb\n","    p = 1013.\n","\n","    e_s = calculate_vapour_pressure_saturated(surf_temp)\n","    e_a = calculate_vapour_pressure_air(rel_hum, air_temp)\n","    return -rho_a * c_E * lambda_v * U_10 * (omega / p) * (e_s - e_a)\n","\n","def calculate_energy_fluxes(phys, surf_temps, combine_days):    \n","    e_s = 0.985 # emissivity of water, given by Jordan\n","    alpha_sw = 0.07 # shortwave albedo, given by Jordan Read\n","    alpha_lw = 0.03 # longwave, albeda, given by Jordan Read\n","    sigma = 5.67e-8 # Stefan-Baltzmann constant\n","    R_sw_arr = phys[:-1,2] + (phys[1:,2] - phys[:-1,2]) / 2\n","    R_lw_arr = phys[:-1,3] + (phys[1:,3] - phys[:-1,3]) / 2\n","    R_lw_out_arr = e_s * sigma * (torch.pow(surf_temps[:] + 273.15, 4))\n","    R_lw_out_arr = R_lw_out_arr[:-1] + (R_lw_out_arr[1:] - R_lw_out_arr[:-1]) / 2\n","\n","    air_temp = phys[:-1,4] \n","    air_temp2 = phys[1:,4]\n","    rel_hum = phys[:-1,5]\n","    rel_hum2 = phys[1:,5]\n","    ws = phys[:-1, 6]\n","    ws2 = phys[1:,6]\n","    t_s = surf_temps[:-1]\n","    t_s2 = surf_temps[1:]\n","    E = calculate_heat_flux_latent(t_s, air_temp, rel_hum, ws)\n","    H = calculate_heat_flux_sensible(t_s, air_temp, rel_hum, ws)\n","    E2 = calculate_heat_flux_latent(t_s2, air_temp2, rel_hum2, ws2)\n","    H2 = calculate_heat_flux_sensible(t_s2, air_temp2, rel_hum2, ws2)\n","    E = (E + E2) / 2\n","    H = (H + H2) / 2\n","    fluxes = (R_sw_arr[:-1] * (1-alpha_sw) + R_lw_arr[:-1] * (1-alpha_lw) - R_lw_out_arr[:-1] + E[:-1] + H[:-1])\n","    return fluxes\n","\n","def calculate_ec_loss(inputs, outputs, phys, depth_areas, n_depths, ec_threshold, combine_days=1):\n","    # description: calculates energy conservation loss\n","    # parameters: \n","        # @inputs: features\n","        # @outputs: labels\n","        # @phys: features(not standardized) of sw_radiation, lw_radiation, etc\n","        # @ labels modeled temp (will not used in loss, only for test) !!! DO NOT MODIFY THIS LINE !!!\n","        # @depth_areas: cross-sectional area of each depth\n","        # @n_depths: number of depths\n","        # @use_gpu: gpu flag\n","        # @combine_days: how many days to look back to see if energy is conserved\n","    #*********************************************************************************\n","    n_sets = int(inputs.shape[0] / n_depths)\n","    densities = transformTempToDensity(outputs)\n","    diff_per_set_r = torch.empty(n_sets) \n","    for i in range(n_sets):\n","        # loop through sets of n_depths\n","        # indices\n","        start_index = i * n_depths\n","        end_index = (i + 1) * n_depths\n","        # calculate lake energy for each timestep\n","        lake_energies = calculate_lake_energy(outputs[start_index:end_index, :], densities[start_index:end_index, :], depth_areas)\n","        # calculate energy change in each timestep\n","        lake_energy_deltas = calculate_lake_energy_deltas(lake_energies, combine_days, depth_areas[0])\n","        lake_energy_deltas = lake_energy_deltas[1:]\n","        # calculate sum of energy flux into or out of the lake at each timestep\n","        lake_energy_fluxes = calculate_energy_fluxes(phys[start_index, :, :], outputs[start_index, :], combine_days)\n","        ### can use this to plot energy delta and flux over time to see if they line up\n","        diff_vec = torch.abs(lake_energy_deltas - lake_energy_fluxes) \n","        tmp_mask = 1 # - phys[start_index+1, 1:-1, 9] \n","        tmp_loss = torch.mean(diff_vec * tmp_mask)\n","        diff_per_set_r[i] = tmp_loss \n","    diff_per_set = torch.clamp(diff_per_set_r - ec_threshold, min=0, max=999999)\n","    return torch.mean(diff_per_set), diff_vec, diff_per_set_r, diff_per_set \n"]},{"cell_type":"markdown","metadata":{"id":"NNygPr93qYCx"},"source":["## Load data\n","\n","Here we load the data for pretraining and partition the data into training, validation and test sets. "]},{"cell_type":"code","execution_count":9,"metadata":{"id":"RmNNJ6lhDSG8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645564170850,"user_tz":300,"elapsed":3268,"user":{"displayName":"Nan Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08028572488762231768"}},"outputId":"1beeb550-2de3-4fec-a405-e86ef122602f"},"outputs":[{"output_type":"stream","name":"stdout","text":["The shape of x_full is (50, 12691, 9)\n","The shape of x_raw_full is (50, 12691, 9)\n","The shape of diag_full is (50, 12691, 3)\n","The shape of label is (50, 12691)\n","The shape of x_train is (950, 423, 9)\n","The shape of y_train is (950, 423)\n","The shape of p_train is (950, 423, 10)\n","The shape of m_train is (950, 423)\n"]}],"source":["# load data\n","x_full = np.load(data_dir + '/processed_features.npy') #standardized inputs\n","x_raw_full = np.load(data_dir + '/features.npy') #raw inputs\n","diag_full = np.load(data_dir + '/diag.npy') \n","label_full = np.load(data_dir + '/labels.npy') #simulated lake temperatures\n","\n","# process data\n","mask_full = np.ones(label_full.shape) # no missing values to mask for simulated data\n","phy_full = np.concatenate((x_raw_full[:,:,:(-2)], diag_full), axis=2) \n","## phy: 4-air temp, 5-rel hum, 6-wind speed, 9-ice flag\n","\n","# print the shape\n","print(f\"The shape of x_full is {np.shape(x_full)}\")\n","print(f\"The shape of x_raw_full is {np.shape(x_raw_full)}\")\n","print(f\"The shape of diag_full is {np.shape(diag_full)}\")\n","print(f\"The shape of label is {np.shape(label_full)}\")\n","\n","# train-val split\n","## in model pretraining, we use validation set to find the best number of steps \n","## Here we use equal size for train-val split\n","## They can be of different sizes by using different n_steps \n","N = np.shape(x_full)[1] # the total number of samples\n","idx_tr, idx_va, idx_te = (int(N/3), int(N/3*2), N)\n","\n","\n","## training\n","x_tr = x_full[:, :idx_tr]\n","y_tr = label_full[:, :idx_tr]\n","p_tr = phy_full[:, :idx_tr]\n","m_tr = mask_full[:, :idx_tr]\n","## validation\n","x_va = x_full[:, idx_tr:idx_va]\n","y_va = label_full[:, idx_tr:idx_va]\n","p_va = phy_full[:, idx_tr:idx_va]\n","m_va = mask_full[:, idx_tr:idx_va]\n","\n","# create data\n","n_steps = int(idx_tr/npic)\n","x_train = np.zeros([n_depths * N_sec, n_steps, input_size])\n","y_train = np.zeros([n_depths * N_sec, n_steps])\n","p_train = np.zeros([n_depths * N_sec, n_steps, phy_size])\n","m_train = np.zeros([n_depths * N_sec, n_steps])\n","\n","x_val = np.zeros([n_depths * N_sec, n_steps, input_size])\n","y_val = np.zeros([n_depths * N_sec, n_steps])\n","p_val = np.zeros([n_depths * N_sec, n_steps, phy_size])\n","m_val = np.zeros([n_depths * N_sec, n_steps])\n","\n","\n","for i in range(1, N_sec + 1):\n","    r_1 = int((i - 1) * n_steps / 2) ## stride size = n_steps / 2\n","    r_2 = r_1 + n_steps ## step size = n_step\n","    x_train[(i-1)*n_depths:(i*n_depths)] = x_tr[:, r_1:r_2]\n","    y_train[(i-1)*n_depths:(i*n_depths)] = y_tr[:, r_1:r_2]\n","    p_train[(i-1)*n_depths:(i*n_depths)] = p_tr[:, r_1:r_2]\n","    m_train[(i-1)*n_depths:(i*n_depths)] = m_tr[:, r_1:r_2]\n","    x_val[(i-1)*n_depths:(i*n_depths)] = x_va[:, r_1:r_2]\n","    y_val[(i-1)*n_depths:(i*n_depths)] = y_va[:, r_1:r_2]\n","    p_val[(i-1)*n_depths:(i*n_depths)] = p_va[:, r_1:r_2]\n","    m_val[(i-1)*n_depths:(i*n_depths)] = m_va[:, r_1:r_2]\n","\n","x_f = np.concatenate((x_train, x_val), axis=0)\n","y_f = np.concatenate((y_train, y_val), axis=0)\n","p_f = np.concatenate((p_train, p_val), axis=0)\n","m_f = np.concatenate((m_train, m_val), axis=0)\n","\n","# print the shape\n","print(f\"The shape of x_train is {np.shape(x_train)}\")\n","print(f\"The shape of y_train is {np.shape(y_train)}\")\n","print(f\"The shape of p_train is {np.shape(p_train)}\")\n","print(f\"The shape of m_train is {np.shape(m_train)}\")\n"]},{"cell_type":"markdown","metadata":{"id":"HlT2ADUu4Ose"},"source":["## Class definition of LSTM model\n","We set up a relatively standard LSTM network. See [the PyTorch tutorial on LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html) for details. "]},{"cell_type":"code","execution_count":10,"metadata":{"id":"ETRrJq8n_p97","executionInfo":{"status":"ok","timestamp":1645564183739,"user_tz":300,"elapsed":88,"user":{"displayName":"Nan Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08028572488762231768"}}},"outputs":[],"source":["class LSTMnet(nn.Module):\n","    def __init__(self, input_dim, output_dim, hidden_dim, n_layers):\n","        super(LSTMnet, self).__init__()\n","        self.output_size = output_dim\n","        self.n_layers = n_layers\n","        self.hidden_dim = hidden_dim\n","        self.lstm = nn.LSTM(input_size = input_dim, \n","                            hidden_size = hidden_dim, \n","                            num_layers = n_layers, \n","                            batch_first=True)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","        \n","    def forward(self, x):\n","        batch_size = x.size(0)\n","        lstm_out, hidden = self.lstm(x)\n","        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n","        out = self.fc(lstm_out)\n","        out = out.view(batch_size, -1)\n","        return out"]},{"cell_type":"markdown","metadata":{"id":"YXSkSUSRmm0N"},"source":["## Function definitions for Deep Learning\n","\n","In the training, the loss funcation is a weighted sum of the *prediction error* loss and *energy conservation* loss. The algorithm processes a mini batch of data at a time and use backpropagation to update model parameters. The training intends to run the specified number of epochs but will stop *early* if the returned loss increases for three consequential updates. "]},{"cell_type":"code","execution_count":11,"metadata":{"id":"8jvWQQCFGaDP","executionInfo":{"status":"ok","timestamp":1645564189932,"user_tz":300,"elapsed":344,"user":{"displayName":"Nan Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08028572488762231768"}}},"outputs":[],"source":["def weighted_rmse_loss(input, target, weight):\n","    # defined weighted rmse loss\n","    # used in model training\n","    return torch.sqrt(torch.sum(weight * (input - target) ** 2) / torch.sum(weight))\n","\n","def batch_sample_generator(size_list, batch_size):\n","    ## create advanced batches for training-val-test\n","    ## each batch should match with depth_areas for calculating ec_loss\n","    n_batch = int(size_list / batch_size)\n","    n_remain = size_list % batch_size\n","    batch_sampler = [list(range(i * batch_size, i * batch_size + batch_size)) for i in range(n_batch)]\n","    if n_remain > 0:\n","        batch_sampler += [list(range(n_batch * batch_size, n_batch * batch_size + n_remain))]\n","    return batch_sampler\n","\n","\n","def train(model, epochs, optimizer, train_loader, valid_loader, early_stopping=True):\n","    the_last_loss = 100\n","    trigger_times = 0\n","    for i in range(epochs):\n","        print('This is epoch ' + str(i + 1))\n","        for batch, (x, y, m, p) in enumerate(train_loader):\n","            model.train()\n","            size = len(train_loader.dataset)\n","            x = x.to(device).float()\n","            y = y.to(device)\n","            m = m.to(device)\n","            p = p.to(device)\n","            # Compute prediction and loss\n","            pred = model(x)\n","            loss_1 = weighted_rmse_loss(pred, y, m)\n","            loss_2, a, b, c = calculate_ec_loss(x,\n","                                        pred,\n","                                        p,                                     \n","                                        depth_areas,\n","                                        n_depths,\n","                                        ec_threshold,\n","                                        combine_days=1)\n","            loss = loss_1 + elam * loss_2\n","            # Backpropagation\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            # Print output\n","            loss_track, current = loss.item(), batch * len(x)\n","            if batch%5 == 0:\n","                print(\"BatLoss = \" + \"{:.4f}\".format(loss) + \\\n","                    \", Rc = \" + \"{:.4f}\".format(loss_1) + \\\n","                    \", Ec = \" + \"{:.4f}\".format(loss_2) + \\\n","                    f'[{current:>5d}/{size:>5d}]')\n","        \n","        # Early stopping\n","        if early_stopping:\n","            the_current_loss = val_test(model, valid_loader)\n","            print('The current loss:', the_current_loss)\n","            if the_current_loss > the_last_loss:\n","                trigger_times += 1\n","                if trigger_times >= patience:\n","                    print('Early stopping!\\nStart to test process.')\n","                    return model, (i+1)\n","            else:\n","                trigger_times = 0 ## reset trigger time to 0\n","                the_last_loss = the_current_loss\n","\n","    return model, epochs\n","        \n","\n","def val_test(model, data_loader):\n","    # Settings\n","    model.eval()\n","\n","    loss_total = 0\n","    # make predictions on validation/test data\n","    with torch.no_grad():\n","        for batch, (x, y, m, p) in enumerate(data_loader):\n","            x = x.to(device).float()\n","            y = y.to(device)\n","            m = m.to(device)\n","            p = p.to(device)\n","\n","            # Compute prediction and loss\n","            pred = model(x)\n","            loss_1 = weighted_rmse_loss(pred, y, m)\n","            loss_2, a, b, c = calculate_ec_loss(x,\n","                                        pred,\n","                                        p,                                     \n","                                        depth_areas,\n","                                        n_depths,\n","                                        ec_threshold,\n","                                        combine_days=1)\n","            loss = loss_1 + elam * loss_2\n","            loss_total += loss.item()\n","    return loss_total / len(data_loader)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"yT_XdYsit0f9"},"source":["## Create data loaders"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JVKzySyqtz7k"},"outputs":[],"source":["train_data = TensorDataset(torch.from_numpy(x_train), \n","                           torch.from_numpy(y_train), \n","                           torch.from_numpy(m_train),\n","                           torch.from_numpy(p_train))\n","\n","val_data = TensorDataset(torch.from_numpy(x_val), \n","                         torch.from_numpy(y_val), \n","                         torch.from_numpy(m_val),\n","                         torch.from_numpy(p_val))\n","\n","full_data = TensorDataset(torch.from_numpy(x_f), \n","                          torch.from_numpy(y_f), \n","                          torch.from_numpy(m_f),\n","                          torch.from_numpy(p_f))\n","\n","tr_loader = DataLoader(train_data, batch_sampler=batch_sample_generator(len(train_data), batch_size))\n","va_loader = DataLoader(val_data, batch_sampler=batch_sample_generator(len(val_data), batch_size))\n","fu_loader = DataLoader(full_data, batch_sampler=batch_sample_generator(len(full_data), batch_size))"]},{"cell_type":"markdown","metadata":{"id":"I2wL-ZCGmq6o"},"source":["## Training with early-stopping"]},{"cell_type":"markdown","metadata":{"id":"AU051Gg0E9TS"},"source":["Here we train the model with early stopping. That is, if the model "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MkR75nmuKeHA"},"outputs":[],"source":["# train the model with early stopping\n","## initialize model\n","net = LSTMnet(input_dim = input_size, output_dim = 1, hidden_dim = state_size, n_layers = 1).to(device)\n","optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n","net, best_epoch = train(net, epochs, optimizer, tr_loader, va_loader)"]},{"cell_type":"markdown","metadata":{"id":"fbR8wABNmuE5"},"source":["## Retrain with best parameters\n","During the training, the training segment and validation segment were used separately to identify the best epochs. Once a best set of paramemters are identified based on the loss evaluated using the validation set, the model should be retrained using the combined training and validation set to have the best estimation efficiency. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R3u8fI0SMCJr"},"outputs":[],"source":["# optional: retrain the model using the best #epochs over train+val\n","## initialize model\n","net = LSTMnet(input_dim = input_size, output_dim = 1, hidden_dim = state_size, n_layers = 1).to(device)\n","optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n","net, _ = train(net, best_epoch, optimizer, fu_loader, fu_loader, early_stopping=False)\n","## save the model"]},{"cell_type":"markdown","metadata":{"id":"0ZHC1FObH6P4"},"source":["Save the trained model in the output folder for future use. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YJgRhc7DH3XW"},"outputs":[],"source":["torch.save(net, output_dir + 'model_pretrain.pt') ## save it in the output folder"]},{"cell_type":"markdown","metadata":{"id":"UiflUZazsA81"},"source":["# Part II.  PGRNN Training \n","\n","In this part, we *re-train* the model using observed data. The real data has missing observations, which will be *masked* in the loss calculation. "]},{"cell_type":"markdown","metadata":{"id":"mlyRTEYcshG-"},"source":["## Load data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3fWb1GK6vH1P"},"outputs":[],"source":["# load data ---------------------------------------------------------------\n","x_full = np.load(data_dir + 'processed_features.npy') # input data\n","x_raw_full = np.load(data_dir + 'features.npy') # raw input data\n","diag_full = np.load(data_dir + 'diag.npy')\n","label = np.load(data_dir + 'Obs_temp.npy') # real observation data\n","mask = np.load(data_dir + 'Obs_mask.npy') # flags of missing values\n","phy_full = np.concatenate((x_raw_full[:,:,:-2], diag_full), axis = 2) #physics variables\n","\n","# train-val-test split\n","## Here we use equal size for train-val-test split\n","## They can be of different sizes by using different n_steps \n","idx_tr, idx_va, idx_te = (4000, 8000, 12000)\n","print(idx_tr, idx_va, idx_te)\n","\n","## training\n","x_tr = x_full[:, :idx_tr]\n","y_tr = label[:, :idx_tr]\n","p_tr = phy_full[:, :idx_tr]\n","m_tr = mask[:, :idx_tr]\n","## validation\n","x_va = x_full[:, idx_tr:idx_va]\n","y_va = label[:, idx_tr:idx_va]\n","p_va = phy_full[:, idx_tr:idx_va]\n","m_va = mask[:, idx_tr:idx_va]\n","\n","\n","## testing\n","x_te = x_full[:, idx_va:idx_te]\n","y_te = label[:, idx_va:idx_te]\n","p_te = phy_full[:, idx_va:idx_te]\n","m_te = mask[:, idx_va:idx_te]\n","\n","# sparsify mask\n","\n","s_perc =0.99 #0.002 #0.2#0.4 #0.6 #0.8\n","## training\n","m_tr = np.reshape(m_tr, (-1, 1))\n","loc_tr = np.random.choice(np.arange(m_tr.shape[0]), replace=False, size=int(m_tr.shape[0] * (1-s_perc)))\n","m_tr[loc_tr, 0] = 0.0\n","## validation\n","m_va = np.reshape(m_va, (-1, 1))\n","loc_va = np.random.choice(np.arange(m_va.shape[0]), replace=False, size=int(m_va.shape[0] * (1-s_perc)))\n","m_va[loc_va, 0] = 0.0\n","## reshaping\n","m_tr = np.reshape(m_tr, (50, -1))\n","m_va = np.reshape(m_va, (50, -1))\n","\n","# create data\n","n_steps = int(idx_tr/npic)\n","x_train = np.zeros([n_depths * N_sec, n_steps, input_size])\n","y_train = np.zeros([n_depths * N_sec, n_steps])\n","p_train = np.zeros([n_depths * N_sec, n_steps, phy_size])\n","m_train = np.zeros([n_depths * N_sec, n_steps])\n","\n","x_val = np.zeros([n_depths * N_sec, n_steps, input_size])\n","y_val = np.zeros([n_depths * N_sec, n_steps])\n","p_val = np.zeros([n_depths * N_sec, n_steps, phy_size])\n","m_val = np.zeros([n_depths * N_sec, n_steps])\n","\n","x_test = np.zeros([n_depths * N_sec, n_steps, input_size])\n","y_test = np.zeros([n_depths * N_sec, n_steps])\n","p_test = np.zeros([n_depths * N_sec, n_steps, phy_size])\n","m_test = np.zeros([n_depths * N_sec, n_steps])\n","\n","for i in range(1, N_sec + 1):\n","    r_1 = int((i - 1) * n_steps / 2) ## stride size = n_steps / 2\n","    r_2 = r_1 + n_steps ## step size = n_step\n","    x_train[(i-1)*n_depths:(i*n_depths)] = x_tr[:, r_1:r_2]\n","    y_train[(i-1)*n_depths:(i*n_depths)] = y_tr[:, r_1:r_2]\n","    p_train[(i-1)*n_depths:(i*n_depths)] = p_tr[:, r_1:r_2]\n","    m_train[(i-1)*n_depths:(i*n_depths)] = m_tr[:, r_1:r_2]\n","    x_val[(i-1)*n_depths:(i*n_depths)] = x_va[:, r_1:r_2]\n","    y_val[(i-1)*n_depths:(i*n_depths)] = y_va[:, r_1:r_2]\n","    p_val[(i-1)*n_depths:(i*n_depths)] = p_va[:, r_1:r_2]\n","    m_val[(i-1)*n_depths:(i*n_depths)] = m_va[:, r_1:r_2]\n","    x_test[(i-1)*n_depths:(i*n_depths)] = x_te[:, r_1:r_2]\n","    y_test[(i-1)*n_depths:(i*n_depths)] = y_te[:, r_1:r_2]\n","    p_test[(i-1)*n_depths:(i*n_depths)] = p_te[:, r_1:r_2]\n","    m_test[(i-1)*n_depths:(i*n_depths)] = m_te[:, r_1:r_2]\n","\n","x_f = np.concatenate((x_train, x_val), axis=0)\n","y_f = np.concatenate((y_train, y_val), axis=0)\n","p_f = np.concatenate((p_train, p_val), axis=0)\n","m_f = np.concatenate((m_train, m_val), axis=0)"]},{"cell_type":"markdown","metadata":{"id":"FqUHyeSdQXTQ"},"source":["## Create data loaders"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cY8_97uA66gw"},"outputs":[],"source":["train_data = TensorDataset(torch.from_numpy(x_train), \n","                           torch.from_numpy(y_train), \n","                           torch.from_numpy(m_train),\n","                           torch.from_numpy(p_train))\n","\n","val_data = TensorDataset(torch.from_numpy(x_val), \n","                         torch.from_numpy(y_val), \n","                         torch.from_numpy(m_val),\n","                         torch.from_numpy(p_val))\n","\n","test_data = TensorDataset(torch.from_numpy(x_test), \n","                           torch.from_numpy(y_test), \n","                           torch.from_numpy(m_test),\n","                           torch.from_numpy(p_test))\n","\n","full_data = TensorDataset(torch.from_numpy(x_f), \n","                          torch.from_numpy(y_f), \n","                          torch.from_numpy(m_f),\n","                          torch.from_numpy(p_f))\n","\n","tr_loader = DataLoader(train_data, batch_sampler=batch_sample_generator(len(train_data), batch_size))\n","va_loader = DataLoader(val_data, batch_sampler=batch_sample_generator(len(val_data), batch_size))\n","te_loader = DataLoader(test_data, batch_sampler=batch_sample_generator(len(test_data), batch_size))\n","fu_loader = DataLoader(full_data, batch_sampler=batch_sample_generator(len(full_data), batch_size))"]},{"cell_type":"markdown","metadata":{"id":"TAQiv6zrQbtx"},"source":["## Training with early stopping"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bwh4if7ShNf5"},"outputs":[],"source":["# train the model with early stopping\n","## initialize model\n","net = torch.load(output_dir + 'model_pretrain.pt').to(device)\n","optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n","net, best_epoch = train(net, epochs, optimizer, tr_loader, va_loader)"]},{"cell_type":"markdown","metadata":{"id":"mTnhbev4Qez9"},"source":["## Retrain with training + validation using best parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xlsgetyVUevG"},"outputs":[],"source":["# optional: retrain the model using the best #epochs over train+val\n","## initialize model\n","net = torch.load(output_dir + 'model_pretrain.pt').to(device)\n","optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n","net, _ = train(net, best_epoch, optimizer, fu_loader, fu_loader, early_stopping=False)\n","## save the model\n","torch.save(net, output_dir + 'model_finetune.pt') ## we save it in the data folder for simplicity, you can choose to save it in a different folder"]},{"cell_type":"markdown","metadata":{"id":"UfKsrBezQnKa"},"source":["## Evaluation over test set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tcEvgboZUeqQ"},"outputs":[],"source":["# evaluate the performance over test set\n","net = torch.load(output_dir + 'model_finetune.pt').to(device)\n","net.eval()\n","print('Test loss is:', val_test(net, te_loader))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e2iqRtHNUTyX"},"outputs":[],"source":["# if there is no finetune\n","net = torch.load(output_dir + 'model_pretrain.pt').to(device)\n","net.eval()\n","print('Test loss is:', val_test(net, te_loader))"]},{"cell_type":"markdown","metadata":{"id":"PzgSNLcIBVmY"},"source":["## Visualizations\n","\n","In the following we create a few visualization of the data and model outputs to demonstrate the performance of the models. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nLwxhYq_hKvZ"},"outputs":[],"source":["# load the dates information\n","dates_arr = np.load(data_dir + 'dates.npy')\n","dates_d = dates_arr.astype('M8[D]') ## transform the dates to date\n","dates_m = dates_arr.astype('M8[M]') ## transform the dates to date\n","dates_y = dates_arr.astype('M8[Y]') ## transform the dates to year\n","# load features\n","x_raw = np.load(data_dir + 'features.npy')\n","x_proc = np.load(data_dir + 'processed_features.npy')\n","# load the labels\n","label = np.load(data_dir + 'Obs_temp.npy')\n","print('Shape of labels:', label.shape)\n","# load the weight\n","weight = np.load(data_dir + 'Obs_mask.npy')\n","print('Shape of weight:', weight.shape)\n","print('Mean of weight:', np.mean(weight)) ## data is very sparse, 2% of the data are not nan\n","# filter the test set\n","label_test = label[:, idx_va:idx_te]\n","weight_test = weight[:, idx_va:idx_te]\n","dates_test_d = dates_d[idx_va:idx_te]\n","dates_test_m = dates_m[idx_va:idx_te]\n","dates_test_y = dates_y[idx_va:idx_te].astype(str)\n","print('Years available:', np.unique(dates_test_y))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bi1vLv5pwZ26"},"outputs":[],"source":["ice_mask = phy_full[:,:,9]\n","ice_mask_test = ice_mask[:, idx_va:idx_te]\n","label_test = label[:, idx_va:idx_te]*ice_mask_test\n","weight_test = weight[:, idx_va:idx_te]*ice_mask_test\n","print(ice_mask.shape)\n","print(ice_mask_test.shape)\n","#print(np.where(ice_mask==1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mCXvzzlmeXqv"},"outputs":[],"source":["# visualize the weight\n","## black: data, white: zero-weight (NA value?)\n","idx = np.where(dates_test_y.astype(int)>= 2002)[0]\n","n_row = label_test.shape[0]\n","n_col = len(idx)\n","## make the figure\n","fig, ax = plt.subplots(figsize=(10, 5))\n","im = ax.imshow(weight_test[:, idx] == 0, aspect='auto', cmap=plt.cm.gray)\n","x_choose = np.array(np.linspace(0, 1, 8) * (n_col-1), dtype=int)\n","ax.set_xticks(x_choose)\n","ax.set_xticklabels(dates_test_d[idx][x_choose], rotation=30, fontdict={'horizontalalignment': 'center'})\n","ax.set_xlabel('Date')\n","y_choose = np.array(np.linspace(0, 1, 8) * (n_row-1), dtype=int)\n","ax.set_yticks(y_choose)\n","ax.set_yticklabels(np.around(np.linspace(x_raw[0, 0, 1], x_raw[-1, -1, 1], n_row)[y_choose], decimals=1))\n","ax.set_ylabel('Depth')\n","ax.set_title('Sample Weight')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"isIojKG8jqdh"},"outputs":[],"source":["# visualize the true values\n","import matplotlib\n","weight_mat = weight_test[:, idx]\n","weight_sum = np.sum(weight_mat, axis=0)\n","idx_dt = np.where(weight_sum > 0)[0]\n","n_col = len(idx_dt)\n","label_mat = label_test[:, idx].copy()\n","label_mat[weight_test[:, idx] == 0] = np.nan\n","## make the figure\n","fig, ax = plt.subplots(figsize=(10, 5))\n","cmap = matplotlib.cm.coolwarm\n","cmap.set_bad('black') ## we set the nan values to black, you can change it to other colors\n","im = ax.imshow(label_mat[:, idx_dt], aspect='auto', cmap=cmap)\n","ax.set_xticks(np.arange(n_col))\n","ax.set_xticklabels(dates_test_d[idx][idx_dt], rotation=30, fontdict={'horizontalalignment': 'center'})\n","ax.set_xlabel('Date')\n","y_choose = np.array(np.linspace(0, 1, 8) * (n_row-1), dtype=int)\n","ax.set_yticks(y_choose)\n","ax.set_yticklabels(np.around(np.linspace(x_raw[0, 0, 1], x_raw[-1, -1, 1], n_row)[y_choose], decimals=1))\n","ax.set_ylabel('Depth')\n","ax.set_title('True Values of Ice-covered Days' )\n","fig.colorbar(im, ax=ax)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_dy_8n0xno4n"},"outputs":[],"source":["# visualize the predictions\n","net = torch.load(output_dir + 'model_finetune.pt').to(device)\n","net.eval()\n","with torch.no_grad():\n","    x = torch.from_numpy(x_test).to(device).float()\n","    pred_mat = net(x).cpu().numpy()\n","\n","label_pred = np.zeros(label_test.shape)\n","for i in range(1, N_sec + 1):\n","    r_1 = int((i - 1) * n_steps / 2) ## stride size = n_steps / 2\n","    r_2 = r_1 + n_steps ## step size = n_step\n","    label_pred[:, r_1:r_2] = pred_mat[(i-1)*n_depths:(i*n_depths)].copy()\n","\n","vis_mat = label_pred[:, idx].copy()\n","vis_mat[weight_test[:, idx] == 0] = np.nan\n","## make the figure\n","fig, ax = plt.subplots(figsize=(10, 5))\n","cmap = matplotlib.cm.coolwarm\n","cmap.set_bad('black') ## we set the nan values to black, you can change it to other colors\n","im = ax.imshow(vis_mat[:, idx_dt], aspect='auto', cmap=cmap)\n","ax.set_xticks(np.arange(n_col))\n","ax.set_xticklabels(dates_test_d[idx][idx_dt], rotation=30, fontdict={'horizontalalignment': 'center'})\n","ax.set_xlabel('Date')\n","y_choose = np.array(np.linspace(0, 1, 8) * (n_row-1), dtype=int)\n","ax.set_yticks(y_choose)\n","ax.set_yticklabels(np.around(np.linspace(x_raw[0, 0, 1], x_raw[-1, -1, 1], n_row)[y_choose], decimals=1))\n","ax.set_ylabel('Depth')\n","ax.set_title('Predicted Values of Ice-covered Days' )\n","fig.colorbar(im, ax=ax)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VE7oj4nooC_I"},"outputs":[],"source":["# visualize the residuals = true labels - predicted values\n","err_mat = label_test - label_pred\n","vis_mat = err_mat[:, idx].copy()\n","vis_mat[weight_test[:, idx] == 0] = np.nan\n","## make the figure\n","fig, ax = plt.subplots(figsize=(10, 5))\n","cmap = matplotlib.cm.coolwarm\n","cmap.set_bad('black') ## we set the nan values to black, you can change it to other colors\n","im = ax.imshow(vis_mat[:, idx_dt], aspect='auto', cmap=cmap)\n","ax.set_xticks(np.arange(n_col))\n","ax.set_xticklabels(dates_test_d[idx][idx_dt], rotation=30, fontdict={'horizontalalignment': 'center'})\n","ax.set_xlabel('Date')\n","y_choose = np.array(np.linspace(0, 1, 8) * (n_row-1), dtype=int)\n","ax.set_yticks(y_choose)\n","ax.set_yticklabels(np.around(np.linspace(x_raw[0, 0, 1], x_raw[-1, -1, 1], n_row)[y_choose], decimals=1))\n","ax.set_ylabel('Depth')\n","ax.set_title('Residuals of Ice-covered Days')\n","fig.colorbar(im, ax=ax)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-rMf4FaySH5d"},"outputs":[],"source":["# Part II. visualizations for comparing pretrained model and fine-tuned model\n","net = torch.load(output_dir + 'model_pretrain.pt').to(device)\n","net.eval()\n","with torch.no_grad():\n","    x = torch.from_numpy(x_test).to(device).float()\n","    pred_pret = net(x).cpu().numpy()\n","\n","label_pret = np.zeros(label_test.shape)\n","for i in range(1, N_sec + 1):\n","    r_1 = int((i - 1) * n_steps / 2) ## stride size = n_steps / 2\n","    r_2 = r_1 + n_steps ## step size = n_step\n","    label_pret[:, r_1:r_2] = pred_pret[(i-1)*n_depths:(i*n_depths)].copy()\n","err_pret = label_test - label_pret\n","\n","net = torch.load(output_dir + 'model_finetune.pt').to(device)\n","net.eval()\n","with torch.no_grad():\n","    x = torch.from_numpy(x_test).to(device).float()\n","    pred_fine = net(x).cpu().numpy()\n","\n","label_fine = np.zeros(label_test.shape)\n","for i in range(1, N_sec + 1):\n","    r_1 = int((i - 1) * n_steps / 2) ## stride size = n_steps / 2\n","    r_2 = r_1 + n_steps ## step size = n_step\n","    label_fine[:, r_1:r_2] = pred_fine[(i-1)*n_depths:(i*n_depths)].copy()\n","err_fine = label_test - label_fine"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Okgs5fubSHy0"},"outputs":[],"source":["# visualizatin along different months\n","## keep the month information and transform to int\n","dates_test_m_int = np.array([str(i)[-2:] for i in dates_test_m]).astype(int)\n","RMSE_pret = []\n","RMSE_fine = []\n","for i in range(1, 13):\n","    weight_m = weight_test[:, dates_test_m_int == i]\n","    if weight_m.sum() > 0:\n","        loc_temp = np.where(np.sum(weight_m, axis=1) > 0)[0]\n","        err_pret_m = err_pret[:, dates_test_m_int == i]\n","        RMSE_m = np.sqrt(np.sum(weight_m * err_pret_m ** 2, axis=1)[loc_temp] / np.sum(weight_m, axis=1)[loc_temp])\n","        RMSE_pret.append(list(RMSE_m))\n","\n","        err_fine_m = err_fine[:, dates_test_m_int == i]\n","        RMSE_m = np.sqrt(np.sum(weight_m * err_fine_m ** 2, axis=1)[loc_temp] / np.sum(weight_m, axis=1)[loc_temp])\n","        RMSE_fine.append(list(RMSE_m))\n","\n","plt.figure(figsize=(10, 5))\n","\n","bpl = plt.boxplot(RMSE_pret,positions=6*np.arange(4)-0.5,widths=1)\n","bpr = plt.boxplot(RMSE_fine, positions=6*np.arange(4)+0.5,widths=1)\n","\n","ticks = ['Jan', 'Feb', 'Mar', 'Apr']\n","\n","def define_box_properties(plot_name, color_code, label):\n","\tfor k, v in plot_name.items():\n","\t\tplt.setp(plot_name.get(k), color=color_code)\n","\t\t\n","\t# use plot function to draw a small line to name the legend.\n","\tplt.plot([], c=color_code, label=label)\n","\tplt.legend()\n","\n","\n","# setting colors for each groups\n","define_box_properties(bpl, '#D7191C', 'Pretrained')\n","define_box_properties(bpr, '#2C7BB6', 'Finetuned')\n","plt.legend()\n","# set the x label values\n","plt.xticks(np.arange(0, len(ticks) * 6, 6), ticks)\n","plt.xlabel('Month')\n","plt.ylabel('RMSE')\n","plt.xlim(-3/4, len(ticks) *6 )\n","plt.title('RMSE by Month')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7rSLiaAHE-if"},"outputs":[],"source":["from torch import jit\n","# visualizatin along different depths\n","depth_vec = x_raw[:, 0, 1]\n","RMSE_pret = []\n","RMSE_fine = []\n","for i in range(len(depth_vec)):\n","    RMSE_pret_temp = []\n","    RMSE_fine_temp = []\n","    for j in range(12):\n","        weight_m = weight_test[i, dates_test_m_int == j]\n","        if weight_m.sum() > 0:\n","            err_pret_m = err_pret[i, dates_test_m_int == j]\n","            RMSE_m = np.sqrt(np.sum(weight_m * err_pret_m ** 2) / np.sum(weight_m))\n","            RMSE_pret_temp.append(RMSE_m)\n","\n","            err_fine_m = err_fine[i, dates_test_m_int == j]\n","            RMSE_m = np.sqrt(np.sum(weight_m * err_fine_m ** 2) / np.sum(weight_m))\n","            RMSE_fine_temp.append(RMSE_m)\n","    RMSE_pret.append(RMSE_pret_temp)\n","    RMSE_fine.append(RMSE_fine_temp)\n","\n","plt.figure(figsize=(25, 5))\n","\n","bpl = plt.boxplot(RMSE_pret, positions=6*np.arange(len(depth_vec)) - 1, widths=1)\n","bpr = plt.boxplot(RMSE_fine, positions=6*np.arange(len(depth_vec)) + 1, widths=1)\n","\n","ticks = np.arange(50) / 2\n","\n","# setting colors for each groups\n","define_box_properties(bpl, '#D7191C', 'Pretrained')\n","define_box_properties(bpr, '#2C7BB6', 'Finetuned')\n","plt.legend()\n","# set the x label values\n","plt.xticks(np.arange(0, len(depth_vec) * 6, 6), ticks)\n","plt.xlabel('Depth')\n","plt.ylabel('RMSE')\n","plt.xlim(-3, len(depth_vec) * 6)\n","plt.title('RMSE by Depth')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7U1YmG5-zNPl"},"outputs":[],"source":["dates_test_y"]},{"cell_type":"markdown","metadata":{"id":"EFhKD7ZMpRqP"},"source":["## References\n","+ Read, J. S., Jia, X., Willard, J., Appling, A. P., Zwart, J. A., Oliver, S. K., ... & Kumar, V. (2019). Processguided deep learning predictions of lake water temperature. [Water Resources Research, 55(11), 9173-9190](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2019WR024922).\n","+ Jia, X., Willard, J., Karpatne, A., Read, J., Zwart, J., Steinbach, M., & Kumar, V. (2019, May). Physics guided RNNs for modeling dynamical systems: A case study in simulating lake temperature profiles. [In Proceedings of the 2019 SIAM International Conference on Data Mining (pp. 558-566). Society for Industrial and Applied Mathematics](https://epubs.siam.org/doi/pdf/10.1137/1.9781611975673.63).\n","+ Jia, X., Willard, J., Karpatne, A., Read, J. S., Zwart, J. A., Steinbach, M., & Kumar, V. (2021). Physics-guided machine learning for scientific discovery: An application in simulating lake temperature profiles. [ACM/IMS Transactions on Data Science, 2(3), 1-26](https://dl.acm.org/doi/abs/10.1145/3447814)."]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"ice_covered_EDA.ipynb","provenance":[{"file_id":"https://github.com/leap-stc/LEAPCourse-Climate-Pred-Challenges/blob/main/Project-StarterCodes/Project2-PhysicsML/lib/Lake_PyTorch.ipynb","timestamp":1645293041197}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}